# Data Streaming Fault Tolerance

## 1. Introduction

Apache Flink提供了一种容错机制，可以一致地恢复数据流应用程序的状态。 该机制可确保即使出现故障，程序的状态最终也将恰好一次反映出数据流中的每条记录。 请注意，有一个开关可以至少将担保降级一次（如下所述）。

容错机制连续保留分布式数据流的快照，对于小状态的流式应用，这些快照非常轻量级，可以在不影响性能的情况下频繁绘制。流应用程序的状态存储在可配置的位置(如主节点或HDFS)。

如果程序发生故障(由于机器、网络或者软件异常)，Flink将停止分布式流处理程序。Flink重新启动操作算子，并将其重置为最新的checkpoint；输入流将重置为状态快照，确保重新启动的并行数据流的任何记录都不属于先前的检查点状态。

注意：默认情况下，检查点是禁用的。

注意：为了使该机制实现其全部保证，数据流源（例如消息队列或代理）必须能够将流后退到定义的最近点。 Apache Kafka具有此功能，Flink与Kafka的连接器利用了此功能。 有关Flink连接器提供的保证的更多信息，请参见数据源和接收器的容错保证。

注意：由于Flink的检查点是通过分布式快照实现的，因此我们可以交替使用快照和检查点一词。

## 2. checkpointing

Flink容错机制的核心部分是绘制分布式数据流和操作员状态的一致快照。 这些快照充当一致的检查点，如果发生故障，系统可以回退到这些检查点。 Flink绘制这些快照的机制在“分布式数据流的轻量级异步快照”中进行了介绍。 它的灵感来自于用于分布式快照的标准Chandy-Lamport算法，并特别针对Flink的执行模型进行了量身定制。

### 2.1 Barriers

Barriers是Flink分布式快照中的核心要素，Barriers注入到Data Stream中，并与记录作一起为数据流的一部分流动。Barriers从不超越记录，它们严格按照顺序排列。 Barriers将数据流中的记录分为进入当前快照的记录集和进入下一个快照的记录集。每个Barrier都有快照的ID，并且快照数据在Barrier之前。Barrier不会中断数据流的流动，因此非常轻便。 来自不同快照的多个Barrier可以同时出现在流中，这意味着各种快照可能同时发生。

![](https://ci.apache.org/projects/flink/flink-docs-release-1.10/fig/stream_barriers.svg)

Stream Barriers在数据源处注入数据流中，快照n的Barrier被注入的点(简称$S_n$)是快照中数据覆盖到的源中的位置。例如，在Apache Kafka中，此位置将是分区中最后一条记录的偏移量。 此位置$S_n$将报告给检查点协调员(Flink的JobManager)。

然后，Barries随数据流向下流动，当有中间操作从其所有输入流收到快照n的屏障时，它会将快照n的屏障发射到其所有输出流中。一旦Sink操作符(流式DAG的末尾)从其所有输入流接收到Barries n，便将快照n确认给检查点协调器。所有接收器都确认快照后，就认为快照已完成。

一旦快照n完成，该作业将不再向数据源请求$S_n$之前的记录，因为此时这些记录(及其后代记录)将通过整个数据流拓扑。

![](https://ci.apache.org/projects/flink/flink-docs-release-1.10/fig/stream_aligning.svg)

Operator接收多个输入流需要在快照Barriers对齐输入流，上图说明了这一点：

- 操作一旦从输入流接收到接收到快照Barrier n，就无法处理该流中的任何其他记录，直到它从其他输入流接收到快照Barrier n为止，否则，它将混合属于快照n和属于快照n + 1的记录。
- 快照Barrier n的流被暂时搁置。 从这些流接收到的记录将不进行处理，而是放入输入缓冲区中
- 一旦最后一个流接收到Barrier n，Operator将发出所有阻塞的未发送记录，然后自身发出快照Barrier n
- 此后，它将恢复处理所有输入流中的记录，处理输入缓冲中的记录，然后再处理流中的记录。

### 2.2 State

当操作包含任何形式的状态时，该状态也必须是快照的一部分。操作状态以不同的形式出现：

- 用户自定义状态：由转换函数(如map()或filter()函数)创建和修改的状态。
- 系统状态：此状态指的是操作计算中的数据缓冲区。这种状态的一个典型示例是窗口缓冲区，系统在其中收集/汇总窗口的记录，直到窗口结束为止。

操作在从所有输入流接收到所有快照Barriers的时间点，以及在将屏障发送到其输出流之前，对其状态进行快照。 届时，将对进行Barriers之前记录的所有状态进行更新，并且不依赖于当前Barriers后的记录进行的任何更新。由于快照的状态可能很大，因此将其存储在可配置的状态后端中。 默认情况下，这是JobManager的内存，但对于生产用途，应配置分布式可靠存储(例如HDFS)中。存储状态后，操作确认检查点，将快照Barriers发送到输出流中，继续下一个Barriers，由此往复继续。

现在生成的快照包含：

- 对于每个并行流数据源，快照启动时流中的偏移量/位置
- 对于每一个操作，指向作为快照一部分存储的状态的指针

![](F:/书籍资料/学习笔记/big_data_notes/官网学习/Apache_Flink官网学习/img/checkpointing.svg)

### 2.3 Exactly Once vs. At Least Once

对齐步骤可以向流传输程序增加等待时间。 通常，这种额外的延迟大约是几毫秒，但是我们看到一些异常值的延迟显着增加的情况。 对于要求所有记录始终具有超低延迟(几毫秒)的应用程序，Flink可以进行切换以在检查点期间跳过流对齐。 一旦操作算子从每个输入接收到checkpoint barrier，仍然会绘制检查点快照。

跳过对齐后，即使到达检查点n的某些检查点障碍，操作仍会继续处理所有输入。 这样，操作还可以在获取检查点n的状态快照之前处理属于检查点n + 1的元素。 在还原时，这些记录将作为重复记录出现，因为它们都包含在检查点n的状态快照中，并将作为检查点n之后的数据的一部分进行重放。

## 2.4 Asynchronous State Snapshots

可以让操作算子在存储其状态快照时继续进行处理，从而有效地使状态快照在后台异步发生。为此，操作算子必须能够产生状态对象，该状态对象的存储方式应确保对操作状态的进一步修改不会影响该状态对象。 例如，在RocksDB中使用的写时复制数据结构具有此行为。

在其输入上收到检查点Barriers后，操作算子将开始对其状态进行异步快照复制。它立即对输出发出障碍，并继续进行常规流处理。 后台复制过程完成后，它将向检查点协调器(JobManager)确认检查点。 现在，仅在所有接收器都接收到障碍并且所有有状态操作都确认其已完成备份之后(可能在障碍到达接收器之后)，检查点才完成。

在其输入上收到检查点栅栏后，操作算子将开始对其状态进行异步快照复制，它立即对输出发出栅栏，并继续进行常规流处理。后台复制过程完成后，它将向检查点协调器(JobManager)确认检查点。现在，只有在所有接收器接收到障碍并且所有操作状态以确认完成备份后可(能是在障碍到达接收器之后)，检查点才完成。

有关状态快照的详细信息，请参见[状态后端](https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/state/state_backends.html)。

## 2.5 Recovery

这种机制下恢复非常简单：失败时，Flink选择最新完成的检查点k。然后，系统重新部署整个分布式数据流。并为每个操作算子提供快照，作为检查点k的一部分。设置DataSource从位置$S_k$读取流，如果状态是增量快照，则操作算子将从最新完整快照的状态开始，然后对该状态应用一系列增量快照更新。

有关更多信息，请参见[重新启动策略](https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/restart_strategies.html)。

## 2.6 Operator Snapshot Implementation

操作算子的快照有两部分：同步部分和异步部分。

运算符和状态后端以Java形式提供其快照`FutureTask`。该任务包含同步部分已完成而异步部分未决的状态。然后，异步部分由该检查点的后台线程执行。
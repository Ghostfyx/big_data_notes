# 第13章 流式实时计算引擎

流式数据在实际应用中非常常见，典型的流式数据包括点击日志、监控指标数据、搜索日志等。流式数据往往伴随实时计算需求，即对流式数据进行实时分析，以便尽可能快速地获取有价值的信息。在大数据领域，将针对流式数据进行实时分析的计算引擎称为**流式实时计算引擎**。这类引擎最大的特点是延迟低，即从数据产生到最终处理完成，整个过程用时极短，往往是毫秒级或秒级处理延迟。与批处理计算引擎类似，流式实时计算引擎也需具有良好的容错性、扩展性和编程简易性等特点。目前常用的流式实时计算引擎分为两类：**面向行（row-based）和面向微批处理（micro-batch）**。其中，面向行的流式实时计算引擎的代表是Apache Storm，其典型特点是延迟低，但吞吐率也低；而面向微批处理的流式实时计算引擎的代表是Spark Streaming，其典型特点是延迟高，但吞吐率也高。

## 13.1 概述

### 13.11 产生背景

一个流式计算过程可用图13-1所示概括，一条消息（msg1）到达后，依次经若干用户实现逻辑处理后，将最终结果写入外部系统。每条消息经用户逻辑处理后，会衍生出新的消息（比如msg1衍生出msg2或msg3）。而对于流式计算而言，应保证消息的可靠性：每条消息进入系统后，可以依次完整经历用户定义的逻辑，最终产生期望的结果，而不应因任意故障导致消息处理中断后致使消息处理不完整。

![](./img/13-1.jpg)

​																**图13-1 流式计算过程**

传统的流式计算平台是通过“消息队列+工作进程”组合方式构建的，具体如图13-2所示。流式数据到达系统后：

1. 按照某种预定义的分区策略，被放入若干消息队列中；
2. 由嵌入用户应用逻辑的工作进程从合适的消息队列中读取消息（这里的“消息”指一条流式数据），经处理后，衍生出的消息被重新放入消息队列；
3. 再由另外一类工作进程处理这些新产生的消息；
4. 重复以上过程，直到任意进入系统的消息（或者衍生出的消息），被所有工作进程处理一遍；

![](./img/13-2.jpg)

​															**图13-2 传统流式计算平台**

这类系统能够解决流式数据处理的问题，但是存在以下几个缺点：

- 扩展性差：消息分区以及工作进程分布通过人工完成的，当机器规模增加时，整个系统扩展起来非常烦琐。
- 容错性差：当工作进程因硬件故障或软件bug而失败时，需要人工干预，重启对应的工作进程。当一个消息队列崩溃时，可能面临数据丢失的危险。
- 无法保证数据被处理完：流式处理应用场景通常是对数据处理完整性有一定的要求，即每条数据应至少被处理一次（**at least once**）或仅且仅被处理一次（**exactly once**）。

为了克服传统消息队列系统的不足，新型流式计算引擎诞生了。这类计算引擎为用户提供了简易的编程接口，用户可通过实现这些编程接口即可完成分布式流式应用程序的开发，而其他比较复杂的工作，如节点间的通信、节点失效、数据分片、系统扩展等，全部由运行时环境完成，用户无需关心这些细节。

### 13.1.2 常见开源实现

当前比较主流的流式数据线(Data Pipeline)共分为四步：

![](./img/13-3.jpg)

（1）数据采集：该阶段主要负责从不同的数据源上实时采集数据，典型的数据源包括移动客户端，网站后端等，通常根据后端数据缓存模块不同，选用不同的实现方案，可选的包括Flume以及自定义Kafka Producer。

（2）数据缓冲：为了平衡数据采集和数据处理速率的不对等，通常数据采集阶段和处理阶段之间加入一个数据缓冲阶段，通过由消息队列担任该角色，比如：Kafka

（3）实时分析：流式地从数据缓冲区获取数据，并快速完成数据处理，将结果写到后端的存储系统中。根据系统对**延迟和吞吐率**的要求不同，可选用不同的流式计算引擎，比如Storm或SparkStreaming。

（4）结果存储：将计算产生的结果存储到外存储系统中，根据应用场景不同，可选择不同的存储系统，比如大量可实时查询的系统，可存储到HBase中，小量但需可高并发查询的系统，可存入Redis中。

根据流式计算引擎的数据组织特点，可将其分为两类：基于行（row based）和基于微批处理（micro-batch based）。基于行的流式实时处理系统以行为单位处理数据，其主要优点是单条数据的处理延迟低，但系统吞吐率一般也较低，其典型代表是Apache Storm；基于微批处理的流式实时处理系统则将流式处理转化为批处理，即以批为单位组织数据，它通常以时间为单位将流式数据切割成连续的批数据，并通过批处理的方式处理每批数据，这类系统的优点是吞吐率高，而缺点也很明显：单条数据处理延迟较高，其典型代表是Spark Streaming。

## 13.2 Storm基础与实战

本节将介绍Storm的基本概念、软件架构、程序设计方法以及内部原理。

### 13.2.1 Storm概念与架构

本小节将介绍Storm基本概念，包括：Tuple、Stream、Topology、Bolt和Spout。

**1. 概念**

Storm中核心概念如下：

- Tuple：由一组可序列化的元素构成，每个元素可以是任意类型，包括Java原生类型、String、byte[]、自定义类型(必须是可序列化的)等；
- Stream：无限的Tuple序列对象形成一个Stream，每个Stream由一个唯一ID、一个对Tuple中元素命名的Schema以及无限Tuple构成；
- Topology：Storm中的用户应用程序被称为“Topology”，这类似于MapReduce中的Job。它的英文本意是网络拓扑，是由一些列Spout和Blot构成的DAG(有向无环图)，其中每个点表示一个Spout或Blot，每个边表示Tuple流动方向。
- Spout：Stream的数据源，它通常从外部系统(比如：消息队列)中读取数据，并发射到Topology中。Spout可将数据（Tuple）发射到一个或多个Stream中。
- Blot：消息处理逻辑，可以对接收到的消息做任意处理逻辑，包括：过滤、聚集、与外部数据库通信、消息转换等。Blot可进一步将产生的数据（Tuple）发射到一个或多个Stream中。

在一个Topology中，每个Spout或Blot通常由多个Task组成，每个Spout和Blot的Task相互独立，可以并行执行。如图13-4所示，可类比MapReduce中的job：一个MapReduce Job可看作一个两阶段的DAG，其中Map阶段可分解成多个Map Task, Reduce阶段可分解成多个Reduce Task，相比之下，Storm Topology是一个更加通用的DAG，可以有多个Spout和Blot阶段，每个阶段可进一步分解成多个Task。

 ![](./img/13-4.jpg)

​															**图13-4 Storm的Topology构成**

- Streaming Grouping：Stream Grouping决定了Topology中Tuple在不同Task之间的传递方式。Storm主要提供了多种Stream Grouping实现，常用的有：

	（1）Shuffle Grouping：随机化的轮询方式，即Task产生的Tuple将采用轮询方式发送给下一类组件的Task；

	（2）LoadOrShuffle Grouping：经优化的Shuffle Grouping实现，它使得同一Worker内部的Task优先将Tuple传递给同Worker的其他Task。

	（3）Fields Grouping：某个字段值相同的Tuple将被发送给同一个Task，类似于MapReduce或Spark中的Shuffle实现。

**2. Storm基本架构**

一个Storm集群由三类组件构成：Nimbus、Supervistor和ZooKeeper。，如图13-5所示，它们的功能如下：

![](./img/13-5.jpg)

​																				**图13-5 Storm架构**

- Nimbus：集群管理者和调度组件，通常只有一个，负责代码分发、任务调度、故障监控以及容错 (将失败的任务调度到其他机器上)等，Nimbus是无状态的，可通过“kill -9”杀掉它而不影响正常应用程序的运行。
- Supervistor：计算组件，通常有多个，负责执行实际的计算任务，根据Nimbus指令启动或者停止worker进程。与Nimbus类似，Supervisor也是无状态。
	- Worker：实际的计算进程，每个Supervisor可启动多个Worker进程（需静态为每个Worker分配一个固定端口号），但每个Worker只属于特定的某个Topology。
	- Executor：每个Worker内部可以启动多个Executor，以运行实际的用户逻辑代码(Task)，每个Executor可以运行同类组件（同一个Topology内的Spout或Bolt）中一个或多个Task。
	- Task：用户逻辑代码，由Executor线程根据上下文调用对应的Task计算逻辑。
- Zookeeper：Nimbus与Supervisor之间的协调组件，存储状态信息和运行时统计信息，包括：
	- Supervisor的注册与发现，监控失败的Supervisor。
	- Worker通过Zookeeper向Nimbus发送包含Executor运行状态的心跳信息。
	- Supervisor通过Zookeeper向Nimbus发送包含自己最新状态的心跳信息。
# 第四章 键值操作

键值对RDD是Spark中许多操作需要的常见数据类型，键值对RDD通常用于聚合操作，我们一般要先通过初试ETL（抽取，转换，装载）操作将数据转换为键值对形式。

本章也会讨论用来让用户控制键值对 RDD 在各节点上分布情况的高级特性:分区。有时， 使用可控的分区方式把常被一起访问的数据放到同一个节点上，可以大大减少应用的通信 开销。这会带来明显的性能提升。我们会使用 PageRank 算法来演示分区的作用。为分布 式数据集选择正确的分区方式和为本地数据集选择合适的数据结构很相似——在这两种情 况下，数据的分布都会极其明显地影响程序的性能表现。 

## 4.1 动机

Spark为包含键值对类型的RDD提供了一些专有操作。这些RDD被称为pairRDD，pairRDD是很多程序的构成要素，因为它们提供了并行操作或跨节点重新进行数据分组的操作接口。例如：reduceByKey( )。

## 4.2 创建PairRDD

在Spark中有许多创建PairRDD的方式：1. 很多存储键值对的数据格式会 在读取时直接返回由其键值对数据组成的 pair RDD。2. 普通 RDD 转pair RDD，可以调用 map() 函数来实现，传递的函数需要返回键值对。

构建键值对 RDD 的方法在不同的语言中会有所不同。

- Python了让提取键之后的 数据能够在函数中使用，需要返回一个由二元组组成的 RDD 

	```python
	pairs = lines.map(lambda x: (x.split(" ")[0], x)) # (key, value)形式的数据
	```

- scala为了让提取键之后的数据能够在函数中使用，同样需要返回二元组 

	```scala
	val pairs = lines.map(x => (x.split(" ")(0), x))
	```

- Java 没有自带的二元组类型，因此 Spark 的 Java API 让用户使用 scala.Tuple2 类来创建二 元组。这个类很简单:Java 用户可以通过 new Tuple2(elem1, elem2) 来创建一个新的二元 组，并且可以通过 .__1() 和 ._2() 方法访问其中的元素。 Java 用户还需要调用专门的 Spark 函数来创建 pair RDD。例如，要使用 mapToPair() 函数 来代替基础版的 map() 函数， 

	```java
	PairFunction<String, String, String> keyData =
	       new PairFunction<String, String, String>() {
	       public Tuple2<String, String> call(String x) {
	         return new Tuple2(x.split(" ")[0], x);
	       }
	     };
	JavaPairRDD<String, String> pairs = lines.mapToPair(keyData);
	
	```

## 4.3 PairRDD 转换操作

Pair RDD可以使用标准RDD上所有可用操作，3.4节中的函数传递规则也同样适用，但是PairRDD包含二元组，因此需要传递的函数应该操作二元组而不是独立元素。表 4-1 和表 4-2 总结了对 pair RDD 的一些转化操作 。

​								表4-1:Pair RDD的转化操作(以键值对集合{(1, 2), (3, 4), (3, 6)}为例) 

| 函数名                                                       | 含义                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| reduceByKey(func)                                            | 合并具有相同key的二元组                                      |
| foldByKey(zeroValue: V, numPartitions: Int)                  | foldByKey操作作用于RDD[K,V]根据K将V做折叠、合并处理，其中的参数zeroValue表示先根据映射函数将zeroValue应用与V，进行初始化V，在将映射函数应用于初始化后的V。 |
| groupByKey([*numTasks*])                                     | 对二元组按key分组                                            |
| combineBykey(createCombiner,mergeValue, mergeCombiners, partitioner) |                                                              |
| mapValues(func)                                              | 对 pair RDD 中的每个值应用 一个函数而不改变键                |
| flatMapValues(func)                                          | 对 pair RDD 中的每个值应用 一个返回迭代器的函数，然后 对返回的每个元素都生成一个 对应原键的键值对记录。通常 用于符号化 |
| keys()                                                       | 返回一个仅包含键的 RDD                                       |
| values()                                                     | 返回一个仅包含值的 RDD                                       |
| sortByKey()                                                  | 返回一个根据键排序的 RDD                                     |

​												表4-2:针对两个pair RDD的转化操作 

| 函数名                   | 含义                                                         |
| ------------------------ | ------------------------------------------------------------ |
| subtractByKey(otherRDD)  | 删掉 RDD 中键与 other RDD 中的键相同的元素                   |
| join(otherRDD)           | 对两个 RDD 进行内连接                                        |
| rightOuterJoin(otherRDD) | 对两个 RDD 进行连接操作，确保第一 个 RDD 的键必须存在(右外连接) |
| leftOuterJoin(otherRDD)  | 对两个 RDD 进行连接操作，确保第二 个 RDD 的键必须存在(左外连接) |
| cogroup(otherRDD)        | 将两个 RDD 中拥有相同键的数据分组到一起                      |

Pair RDD 也还是 RDD(元素为 Java 或 Scala 中的 Tuple2 对象或 Python 中的元组)，因此 同样支持 RDD 所支持的函数。例如，我们可以拿前一节中的 pair RDD，筛选掉长度超过 20 个字符的行：

```python
# 例 4-4:用 Python 对第二个元素进行筛选
result = pairs.filter(lambda keyValue: len(keyValue[1]) < 20)
```

```scala
// 例 4-5:用 Scala 对第二个元素进行筛选
pairs.filter{case (key, value) => value.length < 20}
```

```java
// 例 4-6:用 Java 对第二个元素进行筛选
Function<Tuple2<String, String>, Boolean> longWordFilter =
       new Function<Tuple2<String, String>, Boolean>() {
         public Boolean call(Tuple2<String, String> keyValue) {
           return (keyValue._2().length() < 20);
} };
JavaPairRDD<String, String> result = pairs.filter(longWordFilter);
```

下面具体讨论PairRDD的各种函数操作。

### 4.3.1 聚合操作

当数据集以键值对形式组织的时候，聚合具有相同key的元素进行统计是一种常用操作。上一章讲了基础RDD上的fold( )，combine( )，reduce( )等行动操作，PairRDD上也有相对应的键的转换操作。**注意：PairRDD上是转换操作，而不是行动操作**。

reduceByKey( )与reduce( )相类似：都接收一个函数，并使用该函数对值进行合并。reduceByKey( )会为数据集中的每一个键进行并行的归约操作（对应MapReduce计算框架的Reduce），每个归约操作会将键相同的值合并起来，最终返回一个由各键和对应键归约出来的结果值组成的新的 RDD。 

foldByKey( )与fold( )类似：都使用一个与RDD和合并函数中数据类型相同的零值作为初始值，与 fold() 一样，foldByKey() 操作所使用的合并函数对零值与另一 个元素进行合并，结果仍为该元素。 


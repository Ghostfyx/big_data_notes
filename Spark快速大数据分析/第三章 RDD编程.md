# 第三章 RDD编程

本章介绍Spark对数据的核心抽象RDD——弹性分布式数据集（Resilient Distributed Dataset），简称RDD。RDD本质上是分布式的元素集合，在Spark中，对数据的操作不外乎创建RDD，转换RDD和调用RDD值进行求值，一切操作的背后，是Spark将RDD中的数据发送在集群上，将操作并行化执行。

## 3.1 RDD基础

Spark中的RDD是一个不可变的分布式对象集合，每个RDD都被分为多个分区，这些分区运行在集群中的不同节点上，RDD可以包含Python，Java，Scala中的任意类型对象。

用户可以通过两种方式创建RDD：

- 读取外部数据集
- 驱动程序中的对象集合

RDD支持两种类型的操作：

- 转换操作：由一个RDD生成一个新的RDD；
- 行动操作：对RDD计算出一个结果，并把结果返回到驱动器程序中，或存储在外部存储系统，如HDFS。

转换操作和行动操作的区别在于Spark计算RDD的方式不同，用户可以在任何时候定义RDD，但是Spark只会惰性计算RDD，只有在第一次行动操作中用到才会真正的计算。这样的计算适用于大数据领域，如果每次创建和转换RDD的时候立即执行，就会将每次运行的数据存储起来，消耗很多存储空间（这也是Spark速度远快于MapReduce的原因）。

默认情况下，Spark的RDD会在每次进行行动操作时重新计算，如果在多个行动中重用同一个RDD，可以使用RDD.persist( ) 方法持久化RDD。Spark可以将RDD持久化在多个存储介质中，在第一次对持久化的RDD进行计算后，Spark会将RDD数据在内存中（以分区保存在集群上），后续计算会快速读取和计算（减少磁盘寻址，数据加载的时间）。**注意：**如果不需要多次使用同一个RDD，没有必要持久化，浪费存储空间。

在实际操作中，经常会使用persit( )方法将部分数据保存在内存中。总体来说，Spark程序或脚本都会按照下面方式工作：

- 外部数据创建输入RDD
- 使用诸如filter( )等转换操作将输入RDD转化
- 对需要重用的中间结果调用persist( )方法持久化操作
- 使用行动操作触发一次并行化计算，Spark会对计算进行优化后再执行

## 3.2 创建RDD

Spark提供两种创建RDD的方法：

- 外部数据集读取；
- 驱动程序中对一个集合进行并行化

### 3.2.1 并行化创建

把程序中的已有集合传给SparkContext的parellelize( )方法。一般在实际开发和测试中不会使用。

### 3.2.2 外部数据源

详细内容在第五章详细描述

## 3.3 RDD操作

RDD支持转换操作和行动操作，两者区别是行动操作会进行实际计算，将计算结果返回驱动器程序或写入外部存储结果，而且接口API返回值为非RDD的其他数据类型；转换操作是将RDD转换为RDD，接口API的返回值为RDD。

### 3.3.1 转换操作

转换操作几个关键知识点：

- 许多转换操作时针对RDD分区进行操作；
- 转换操作可以操作任意数量的输入RDD；
- 通过转换操作，从已有的RDD中派生出新的RDD，Spark会用谱系图（lineage graph）记录不同RDD之间的依赖关系（宽依赖与窄依赖）。Spark需要用这些依赖信息按需计算每个RDD，也可以在持久化的RDD丢失部分数据时重新计算，恢复丢失数据（例如：部分节点异常，持久化数据丢失，在其他节点并行化计算，将缺失数据重新存储在其他节点中）。

### 3.3.2 行动操作

行动操作几个关键知识点：

- 对RDD进行计算，返回结果或选择将其存储在外部存储介质中，例如：HDFS，Amazon S3；
- collect( )方法在Driver中执行，因此当单台机器内容存放的下数据集时才能使用，不建议在生产中使用，可用与小规模数据集的调试；
- 适当缓存RDD计算的中间结果，因为每次执行行动操作，整个RDD关系链都会从头计算，这样可以避免浪费资源；

### 3.3.3 惰性求值

几个关键知识点：

- RDD在调用行动操作前不会计算，例如：文件读取时，RDD不会立即将文件加载到内存；
- Spark会在内部记录下所有要求执行操作的相关信息，RDD不仅是数据存储结构，而且是记录着计算数据的指令列表；

惰性求值优点：

- 把一些操作合并减少计算步骤；
- 减少文件读写消耗的时间资源和硬件资源。例如在Hadoop MapReduce系统中，需要将中间执行结果临时存储在磁盘中，下一阶段再读取，MapReduce若操作阶段过多，会导致高延时，需要花费大量时间优化；而在Spark中，复杂映射不一定比多个简单连续操作性能更好，用户可以更好关注与数据处理。


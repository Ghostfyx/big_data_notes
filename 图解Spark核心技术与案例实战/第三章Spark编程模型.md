# Spark 编程模型

## 3.3 编程接口

Spark中提供了通用接口来抽象每个RDD，这些接口包括：

- 分区信息：数据集的最小分片

- 依赖关系：指向父RDD

- 函数：基于父RDD的计算方法

- 划分策略和数据位置的元数据

	​                                 						**表3-1 RDD编程接口**

| 操作                    | 含义                                    |
| :---------------------- | :-------------------------------------- |
| Partitions()            | 返回分区对象列表                        |
| PreferredLocations(p)   | 根据数据的本地特性，列出分片p的首选位置 |
| Dependencies()          | 返回依赖列表                            |
| Iterator(p.parentIters) | 给定p的父分片的迭代器，计算分片p的元素  |
| Partitioner()           | 返回说明RDD是否Hash或范围分片的元数据   |

 ### 3.3.1 RDD分区(Partitions)

RDD划分为多个分区分布在集群结点中，分区的多少涉及对这个RDD进行并行计算的粒度。分区是一个逻辑概念，变换前后的新旧分区可能在物理上是同一块内存或硬件存储空间，这种优化防止函数式不变形导致的内存需求无限增长。默认程序分配到的CPU核数；如果从HDFS文件创建，默认文件的数据块数；亦可自定义数量。

### 3.3.2 RDD首选位置

在Spark形成任务有向无环图 DAG时，会尽可能将计算分配到靠近数据的位置，减少网络IO交互。当RDD产生时候存在首选位置，如HDFSRDD分区首选位置是HDFS块所在节点；当RDD分区被缓存，则计算应发送至缓存分区所在节点；回溯RDD“血统”找到具有首选位置属性的父RDD，决定子RDD的分区位置。

### 3.3.3 RDD的依赖关系

在RDD中将依赖分为两种类型：窄依赖于宽依赖。

<img src="https://www.2cto.com/uploadfile/Collfiles/20180210/20180210103654165.png" style="zoom:150%;" />

窄依赖指每个父RDD分区都至多被一个子RDD分区使用，宽依赖指多个子RDD分区依赖一个父RDD分区。例如Map操作是一个窄依赖。

这两种依赖的区别从两个方面来说比较有用：**第一**，窄依赖允许在单个集群节点上流水线式的执行，这个节点可以计算所有父级分区，例如可以逐个元素的执行map和filter操作。相反宽依赖需要所有的父RDD分区数据可用，并且数据通过MapReduce的shuffle完成。**第二**，在窄依赖中，节点失败后的恢复更加高效，因为只有丢失的父类分区需要重新计算，并且这些的父级分区可以并行的在不同节点上重新计算；于此相反，宽依赖的继承关系中，单个失败节点可能导致一个RDD的所有先祖RDD中的一些分区丢失，导致计算的重新执行（宽依赖的子RDD分区依赖多个父RDD分区，在节点A计算子RDD的某个分区数据失败，可能会导致父RDD的多个分区数据重新计算，即导致整个计算任务重新进行，而窄依赖是一对一的关系，只需要重新计算单个父RDD分区即可，不会影响其他分区计算）。

### 3.3.4 RDD分区计算（Iterator）

Spark中的RDD计算式已分区为单位的，而且计算函数都是在对迭代器复合，不需要保存每次计算结果，分区计算一般使用mapPartitions等操作进行，应用于每个分区，即把分区当作一个整体进行处理。

```scala
def mapPartitions[U : ClassTag](f : Iterator[T] => Iterator[U], perservesPartitioning : Boolean = false):RDD[U]
```

f即为输入函数，处理每个分区的数据，每个分区的数据以Iterator[T]传递给函数f，f的输出结果为Iterator[U]，最终RDD由所有分区经过输入函数f处理后的结果合并起来。

### 3.3.5 RDD分区函数（Partitioner）

分区划分对Shuffle类操作很关键，决定了父RDD与子RDD之间的依赖类型（窄依赖or宽依赖）。如果协同划分的话，父子RDD之间形成**一致性分区**安排，保证同一个Key被分配到同一个分区，即窄依赖。反之，则形成宽依赖。一致性分区指的是分区划分器产生分区计算前和后一致的分区安排。

Spark默认提供两种分区划分器：哈希分区划分器（HashPartitioner）和范围划分器（RangePartitioner），且Partitioner值存在于$<K,V>$类型的RDD中！！

## 3.4 创建操作

目前有两种类型的基础RDD：一种是并行集合（Paralleized Collections），接受一个已经存在的Scala集合，然后进行并行计算；另外一种是从外部存储创建RDD，外部存储可以是从文本文件或者HDFS中读取。这两种类型的RDD获取子RDD等一系列拓展，形成**“血统”**关系图。


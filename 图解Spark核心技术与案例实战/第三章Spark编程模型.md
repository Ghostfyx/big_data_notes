# Spark 编程模型

## 3.3 编程接口

Spark中提供了通用接口来抽象每个RDD，这些接口包括：

- 分区信息：数据集的最小分片

- 依赖关系：指向父RDD

- 函数：基于父RDD的计算方法

- 划分策略和数据位置的元数据

	​                                 						**表3-1 RDD编程接口**

| 操作                    | 含义                                    |
| :---------------------- | :-------------------------------------- |
| Partitions()            | 返回分区对象列表                        |
| PreferredLocations(p)   | 根据数据的本地特性，列出分片p的首选位置 |
| Dependencies()          | 返回依赖列表                            |
| Iterator(p.parentIters) | 给定p的父分片的迭代器，计算分片p的元素  |
| Partitioner()           | 返回说明RDD是否Hash或范围分片的元数据   |

 ### 3.3.1 RDD分区(Partitions)

RDD划分为多个分区分布在集群结点中，分区的多少涉及对这个RDD进行并行计算的粒度。分区是一个逻辑概念，变换前后的新旧分区可能在物理上是同一块内存或硬件存储空间，这种优化防止函数式不变形导致的内存需求无限增长。默认程序分配到的CPU核数；如果从HDFS文件创建，默认文件的数据块数；亦可自定义数量。

### 3.3.2 RDD首选位置

在Spark形成任务有向无环图 DAG时，会尽可能将计算分配到靠近数据的位置，减少网络IO交互。当RDD产生时候存在首选位置，如HDFSRDD分区首选位置是HDFS块所在节点；当RDD分区被缓存，则计算应发送至缓存分区所在节点；回溯RDD“血统”找到具有首选位置属性的父RDD，决定子RDD的分区位置。

### 3.3.3 RDD的依赖关系


# 大数据实时架构设计与演进

### 数据处理架构

在流处理器出现之前，数据处理架构主要由批处理器组成，其是对 **无限数据的有限切分**，具有 **吞吐量大、数据较为准确** 的特点。

然而我们知道，批处理器在时间切分点附近 **仍然无法保证数据结果的真实性，且数据的时效性往往比较低，延迟大**。

除了批处理之外，人们为了达到数据生成的高时效性，在数据处理架构中也常常使用微服务来解决，其特点是 **延迟低、无状态、服务与存储分离**。例如：data-connector。

但是微服务无状态的约束很大程度上决定了其并不能很好的应用于现代实时数据处理的需求中，比如准确一次的语义、乱序数据流的处理能力等，它无法满足人们对一个先进的流处理器的想象（在无状态的业务需求中，微服务仍然是最佳选择）。

而要满足人们的这些想象，数据处理架构恰恰需要有 **「状态」** 的概念和相应的机制支持才行。

由此 **有状态的流处理器** 开始逐渐完善并大规模使用。

有状态的流处理器依赖 **高可用可重放的数据源**，通过 **State(状态)提供准确一次的语义**，通过 **时间推理工具能够还原真实世界的数据情况**，广泛应用于 **事件驱动(实时警报)、数据管道(实时数仓)、数据分析(实时报表)** 等业务场景中。

高可用可重放的数据源：

- 持久化的、只添加的
- 写入顺序不可变
- 多个消费者多次消费
- 可信的数据源、可重放

### 开源分布式流处理器

开源流处理器在不断地发展，从一开始只关注低延迟指标到现在兼顾延迟、吞吐与结果准确性，在发展过程中解决了很多问题，编程API的易用性也在不断地提高。

#### 第一代(Storm,JStorm)

- 关注 **毫秒级延迟** 的事件处理
- 数据丢失与处理简单，**容易造成结果不够精确**
- 牺牲了部分的准确性来换取更低的延迟
- 只有底层API接口

#### 第二代(Spark Streaming)

- 更好的容错，**确保在发生故障的时候仅仅处理一次**
- 提供高级API编程接口
- 可能 **牺牲延迟到秒级**
- 结果取决于事件到达的顺序

#### 第三代(Flink)

- **精准一次的语义**，批流都可应用计算
- **兼顾延迟、吞吐与结果准确性**
- **解决了依赖于时间和事件到达顺序的问题**

Lambda架构向Kappa架构的演进。

### 我接触到的实时数据架构

#### 第一代

Spring微服务接Kafka等消息中间件处理MySQL binlog数据。缺点非常明显：复杂数据处理是瓶颈！

#### 第二代

Storm

#### 第三代

Flink